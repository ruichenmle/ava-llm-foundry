name: llama2-13b-sut-nested-list
replicas: 1
command: |- # Note this command is a workaround until we build vllm into the inference image
  python -m venv venv
  source venv/bin/activate
  pip install -r inference_go/requirements.txt
  pip install pyarrow==12.0. ray==2.6.1 pandas==1.5.0 pydantic==1.10.10
  pip install vllm==0.1.3
  pip uninstall torch -y
  pip install torch==2.0.0
compute:
  gpus: 2
  instance: oci.vm.gpu.a10.2
image: mosaicml/inference:0.1.40
cluster: r7z14
default_model:
  checkpoint_path:
    s3_path: s3://mosaicml-68c98fa5-0b21-4c7b-b40b-c4482db8832a/avalaraGPT/model/llama2/13B/raw-sut-nested-list-finetune-r12z3-32gpus-hf/
  model_type: llama2-13b